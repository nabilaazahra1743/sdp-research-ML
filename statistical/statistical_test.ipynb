{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scenario\n",
    "#1. test normalisasi suatu data, apakah distribusinya normal atau tidak-> menggunakn Shapiro-Wilk Test\n",
    "#2. Kalau normal bisa menggunakan t-test, kalau tidak menggunakn Wilcoxon Effect Size \n",
    "#3. Nah keduanya harus ada sample minim 3-5x percobaan untuk membuktikan bahwa nilai akurasinya itu stabil\n",
    "#4. Inisiatif nya bisa dibuat k-fold cross validation dengan membagi data  menjadi 5 bagian dengan iterasi terakhir sebagai testing\n",
    "#5. Hasilnya akan ada 5 nilai akurasi di setiap modelnya yang mana akan dibandingkan antar model satu dengan model lain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: Using Undersampling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package and library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data distribiution data training:  bugs\n",
      "0    593\n",
      "1    458\n",
      "Name: count, dtype: int64\n",
      "data distribiution data testing:  bugs\n",
      "0    286\n",
      "1    239\n",
      "Name: count, dtype: int64\n",
      "Fold 1 - Data Training Undersampled: {0: 593, 1: 458}\n",
      "Fold 1 - Data Validation: {0: 58, 1: 47}\n",
      "Fold 2 - Data Training Undersampled: {0: 593, 1: 458}\n",
      "Fold 2 - Data Validation: {0: 57, 1: 48}\n",
      "Fold 3 - Data Training Undersampled: {0: 593, 1: 458}\n",
      "Fold 3 - Data Validation: {0: 57, 1: 48}\n",
      "Fold 4 - Data Training Undersampled: {0: 593, 1: 458}\n",
      "Fold 4 - Data Validation: {0: 57, 1: 48}\n",
      "Fold 5 - Data Training Undersampled: {0: 593, 1: 458}\n",
      "Fold 5 - Data Validation: {0: 57, 1: 48}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "datasdp = pd.read_csv('D:\\AAAAKK SKRIPSWEETT\\Bismillah Code Skripsi V2\\Dataset\\dataset_sdp_undersampling.csv', delimiter=\";\")\n",
    "\n",
    "X = datasdp.drop(columns=['bugs'])\n",
    "y = datasdp['bugs']\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_base, X_train_meta, y_train_base, y_train_meta = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "counts_training = y_train.value_counts()\n",
    "print(\"data distribiution data training: \", counts_training)\n",
    "counts_testing = y_train_base.value_counts()\n",
    "print(\"data distribiution data testing: \", counts_testing)\n",
    "\n",
    "#insialisasi k-fold validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    print(f\"Fold {fold} - Data Training Undersampled: {y_train.value_counts().to_dict()}\")\n",
    "    print(f\"Fold {fold} - Data Validation: {y_val_fold.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 - Recall: 0.8511\n",
      "Fold 1 - F1 Score: 0.8696\n",
      "Fold 1 - Precision: 0.8889\n",
      "Fold 1 - ROC AUC Score: 0.8824\n",
      "Fold 1 - Accuracy: 0.8857\n",
      "Training fold 2...\n",
      "Fold 2 - Recall: 0.7708\n",
      "Fold 2 - F1 Score: 0.8043\n",
      "Fold 2 - Precision: 0.8409\n",
      "Fold 2 - ROC AUC Score: 0.8240\n",
      "Fold 2 - Accuracy: 0.8286\n",
      "Training fold 3...\n",
      "Fold 3 - Recall: 0.7708\n",
      "Fold 3 - F1 Score: 0.8222\n",
      "Fold 3 - Precision: 0.8810\n",
      "Fold 3 - ROC AUC Score: 0.8416\n",
      "Fold 3 - Accuracy: 0.8476\n",
      "Training fold 4...\n",
      "Fold 4 - Recall: 0.7708\n",
      "Fold 4 - F1 Score: 0.7872\n",
      "Fold 4 - Precision: 0.8043\n",
      "Fold 4 - ROC AUC Score: 0.8065\n",
      "Fold 4 - Accuracy: 0.8095\n",
      "Training fold 5...\n",
      "Fold 5 - Recall: 0.8750\n",
      "Fold 5 - F1 Score: 0.9032\n",
      "Fold 5 - Precision: 0.9333\n",
      "Fold 5 - ROC AUC Score: 0.9112\n",
      "Fold 5 - Accuracy: 0.9143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, precision_score\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi model\n",
    "randomforest_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    randomforest_classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = randomforest_classifier.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi    \n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 - Recall: 0.7660\n",
      "Fold 1 - F1 Score: 0.8090\n",
      "Fold 1 - Precision: 0.8571\n",
      "Fold 1 - ROC AUC Score: 0.8313\n",
      "Fold 1 - Accuracy: 0.8381\n",
      "Training fold 2...\n",
      "Fold 2 - Recall: 0.6667\n",
      "Fold 2 - F1 Score: 0.7111\n",
      "Fold 2 - Precision: 0.7619\n",
      "Fold 2 - ROC AUC Score: 0.7456\n",
      "Fold 2 - Accuracy: 0.7524\n",
      "Training fold 3...\n",
      "Fold 3 - Recall: 0.7708\n",
      "Fold 3 - F1 Score: 0.8315\n",
      "Fold 3 - Precision: 0.9024\n",
      "Fold 3 - ROC AUC Score: 0.8503\n",
      "Fold 3 - Accuracy: 0.8571\n",
      "Training fold 4...\n",
      "Fold 4 - Recall: 0.7083\n",
      "Fold 4 - F1 Score: 0.7473\n",
      "Fold 4 - Precision: 0.7907\n",
      "Fold 4 - ROC AUC Score: 0.7752\n",
      "Fold 4 - Accuracy: 0.7810\n",
      "Training fold 5...\n",
      "Fold 5 - Recall: 0.8125\n",
      "Fold 5 - F1 Score: 0.8571\n",
      "Fold 5 - Precision: 0.9070\n",
      "Fold 5 - ROC AUC Score: 0.8712\n",
      "Fold 5 - Accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "#2. extra trees\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "et_model = ExtraTreesClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    criterion='gini'\n",
    ")\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    et_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = et_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Recall: 0.8085\n",
      "Fold 1 - F1 Score: 0.7835\n",
      "Fold 1 - Precision: 0.7600\n",
      "Fold 1 - ROC AUC Score: 0.8008\n",
      "Fold 1 - Accuracy: 0.8000\n",
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Recall: 0.7500\n",
      "Fold 2 - F1 Score: 0.7579\n",
      "Fold 2 - Precision: 0.7660\n",
      "Fold 2 - ROC AUC Score: 0.7785\n",
      "Fold 2 - Accuracy: 0.7810\n",
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Recall: 0.7708\n",
      "Fold 3 - F1 Score: 0.7400\n",
      "Fold 3 - Precision: 0.7115\n",
      "Fold 3 - ROC AUC Score: 0.7538\n",
      "Fold 3 - Accuracy: 0.7524\n",
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Recall: 0.7917\n",
      "Fold 4 - F1 Score: 0.8085\n",
      "Fold 4 - Precision: 0.8261\n",
      "Fold 4 - ROC AUC Score: 0.8257\n",
      "Fold 4 - Accuracy: 0.8286\n",
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Recall: 0.7917\n",
      "Fold 5 - F1 Score: 0.7835\n",
      "Fold 5 - Precision: 0.7755\n",
      "Fold 5 - ROC AUC Score: 0.7993\n",
      "Fold 5 - Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "#3. Adapative Boosting (AdaaBoost) using smote technique\n",
    "\n",
    "from sklearn.ensemble  import  AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1), \n",
    "    n_estimators=5000,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    adaboost_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = adaboost_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 - Recall: 0.8511\n",
      "Fold 1 - F1 Score: 0.8791\n",
      "Fold 1 - Precision: 0.9091\n",
      "Fold 1 - ROC AUC Score: 0.8910\n",
      "Fold 1 - Accuracy: 0.8952\n",
      "Training fold 2...\n",
      "Fold 2 - Recall: 0.7917\n",
      "Fold 2 - F1 Score: 0.8085\n",
      "Fold 2 - Precision: 0.8261\n",
      "Fold 2 - ROC AUC Score: 0.8257\n",
      "Fold 2 - Accuracy: 0.8286\n",
      "Training fold 3...\n",
      "Fold 3 - Recall: 0.7292\n",
      "Fold 3 - F1 Score: 0.7865\n",
      "Fold 3 - Precision: 0.8537\n",
      "Fold 3 - ROC AUC Score: 0.8120\n",
      "Fold 3 - Accuracy: 0.8190\n",
      "Training fold 4...\n",
      "Fold 4 - Recall: 0.7917\n",
      "Fold 4 - F1 Score: 0.8261\n",
      "Fold 4 - Precision: 0.8636\n",
      "Fold 4 - ROC AUC Score: 0.8432\n",
      "Fold 4 - Accuracy: 0.8476\n",
      "Training fold 5...\n",
      "Fold 5 - Recall: 0.8542\n",
      "Fold 5 - F1 Score: 0.8632\n",
      "Fold 5 - Precision: 0.8723\n",
      "Fold 5 - ROC AUC Score: 0.8745\n",
      "Fold 5 - Accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "#4. Gradient Boosting \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, precision_score, classification_report\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100, \n",
    "    learning_rate=0.1,\n",
    "    min_samples_leaf=2,\n",
    "    max_depth=5,\n",
    "    loss='exponential'\n",
    ")\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    gb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = gb_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 - Recall: 0.8511\n",
      "Fold 1 - F1 Score: 0.8696\n",
      "Fold 1 - Precision: 0.8889\n",
      "Fold 1 - ROC AUC Score: 0.8824\n",
      "Fold 1 - Accuracy: 0.8857\n",
      "Training fold 2...\n",
      "Fold 2 - Recall: 0.8125\n",
      "Fold 2 - F1 Score: 0.8041\n",
      "Fold 2 - Precision: 0.7959\n",
      "Fold 2 - ROC AUC Score: 0.8185\n",
      "Fold 2 - Accuracy: 0.8190\n",
      "Training fold 3...\n",
      "Fold 3 - Recall: 0.7500\n",
      "Fold 3 - F1 Score: 0.7742\n",
      "Fold 3 - Precision: 0.8000\n",
      "Fold 3 - ROC AUC Score: 0.7961\n",
      "Fold 3 - Accuracy: 0.8000\n",
      "Training fold 4...\n",
      "Fold 4 - Recall: 0.7917\n",
      "Fold 4 - F1 Score: 0.8172\n",
      "Fold 4 - Precision: 0.8444\n",
      "Fold 4 - ROC AUC Score: 0.8344\n",
      "Fold 4 - Accuracy: 0.8381\n",
      "Training fold 5...\n",
      "Fold 5 - Recall: 0.8750\n",
      "Fold 5 - F1 Score: 0.8842\n",
      "Fold 5 - Precision: 0.8936\n",
      "Fold 5 - ROC AUC Score: 0.8936\n",
      "Fold 5 - Accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "#5. Histogram Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, precision_score, classification_report\n",
    "\n",
    "hgb_model = HistGradientBoostingClassifier(\n",
    "    max_iter=100,\n",
    "    learning_rate=0.1,\n",
    "    min_samples_leaf=2,\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    hgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = hgb_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 - Recall: 0.7660\n",
      "Fold 1 - F1 Score: 0.8000\n",
      "Fold 1 - Precision: 0.8372\n",
      "Fold 1 - ROC AUC Score: 0.8226\n",
      "Fold 1 - Accuracy: 0.8286\n",
      "Training fold 2...\n",
      "Fold 2 - Recall: 0.8125\n",
      "Fold 2 - F1 Score: 0.7800\n",
      "Fold 2 - Precision: 0.7500\n",
      "Fold 2 - ROC AUC Score: 0.7922\n",
      "Fold 2 - Accuracy: 0.7905\n",
      "Training fold 3...\n",
      "Fold 3 - Recall: 0.7292\n",
      "Fold 3 - F1 Score: 0.7692\n",
      "Fold 3 - Precision: 0.8140\n",
      "Fold 3 - ROC AUC Score: 0.7944\n",
      "Fold 3 - Accuracy: 0.8000\n",
      "Training fold 4...\n",
      "Fold 4 - Recall: 0.7708\n",
      "Fold 4 - F1 Score: 0.8132\n",
      "Fold 4 - Precision: 0.8605\n",
      "Fold 4 - ROC AUC Score: 0.8328\n",
      "Fold 4 - Accuracy: 0.8381\n",
      "Training fold 5...\n",
      "Fold 5 - Recall: 0.8542\n",
      "Fold 5 - F1 Score: 0.8913\n",
      "Fold 5 - Precision: 0.9318\n",
      "Fold 5 - ROC AUC Score: 0.9008\n",
      "Fold 5 - Accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "#6. XGBoost \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, precision_score, classification_report\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=5, \n",
    "    min_child_weight=1, \n",
    "    max_delta_step=0, \n",
    "    random_state=42)\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    xgb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = xgb_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 - Recall: 0.8723\n",
      "Fold 1 - F1 Score: 0.8723\n",
      "Fold 1 - Precision: 0.8723\n",
      "Fold 1 - ROC AUC Score: 0.8844\n",
      "Fold 1 - Accuracy: 0.8857\n",
      "Training fold 2...\n",
      "Fold 2 - Recall: 0.7708\n",
      "Fold 2 - F1 Score: 0.7789\n",
      "Fold 2 - Precision: 0.7872\n",
      "Fold 2 - ROC AUC Score: 0.7977\n",
      "Fold 2 - Accuracy: 0.8000\n",
      "Training fold 3...\n",
      "Fold 3 - Recall: 0.7917\n",
      "Fold 3 - F1 Score: 0.8172\n",
      "Fold 3 - Precision: 0.8444\n",
      "Fold 3 - ROC AUC Score: 0.8344\n",
      "Fold 3 - Accuracy: 0.8381\n",
      "Training fold 4...\n",
      "Fold 4 - Recall: 0.7917\n",
      "Fold 4 - F1 Score: 0.8085\n",
      "Fold 4 - Precision: 0.8261\n",
      "Fold 4 - ROC AUC Score: 0.8257\n",
      "Fold 4 - Accuracy: 0.8286\n",
      "Training fold 5...\n",
      "Fold 5 - Recall: 0.8750\n",
      "Fold 5 - F1 Score: 0.9032\n",
      "Fold 5 - Precision: 0.9333\n",
      "Fold 5 - ROC AUC Score: 0.9112\n",
      "Fold 5 - Accuracy: 0.9143\n"
     ]
    }
   ],
   "source": [
    "#7. Categorical Boosting (CatBoost)\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score, precision_score, classification_report\n",
    "\n",
    "cb_model = CatBoostClassifier(\n",
    "    n_estimators=1000,\n",
    "    loss_function='Logloss',\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    min_data_in_leaf=2,\n",
    "    random_seed=1,\n",
    "    logging_level='Silent')\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    cb_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = cb_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Recall: 0.8723\n",
      "Fold 1 - F1 Score: 0.8913\n",
      "Fold 1 - Precision: 0.9111\n",
      "Fold 1 - ROC AUC Score: 0.9017\n",
      "Fold 1 - Accuracy: 0.9048\n",
      "Training fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Recall: 0.7500\n",
      "Fold 2 - F1 Score: 0.7660\n",
      "Fold 2 - Precision: 0.7826\n",
      "Fold 2 - ROC AUC Score: 0.7873\n",
      "Fold 2 - Accuracy: 0.7905\n",
      "Training fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Recall: 0.7917\n",
      "Fold 3 - F1 Score: 0.8172\n",
      "Fold 3 - Precision: 0.8444\n",
      "Fold 3 - ROC AUC Score: 0.8344\n",
      "Fold 3 - Accuracy: 0.8381\n",
      "Training fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Recall: 0.7917\n",
      "Fold 4 - F1 Score: 0.8172\n",
      "Fold 4 - Precision: 0.8444\n",
      "Fold 4 - ROC AUC Score: 0.8344\n",
      "Fold 4 - Accuracy: 0.8381\n",
      "Training fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Recall: 0.8750\n",
      "Fold 5 - F1 Score: 0.9032\n",
      "Fold 5 - Precision: 0.9333\n",
      "Fold 5 - ROC AUC Score: 0.9112\n",
      "Fold 5 - Accuracy: 0.9143\n"
     ]
    }
   ],
   "source": [
    "#create stacking ensemble\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators_base_model = [\n",
    "    ('randomforest', randomforest_classifier),\n",
    "    ('extratrees', et_model),\n",
    "    ('adaboost', adaboost_model),\n",
    "    ('gradboost', gb_model),\n",
    "    ('hgboost', hgb_model),\n",
    "    ('xgboost', xgb_model),\n",
    "    ('catboost', cb_model), \n",
    "]\n",
    "\n",
    "#stacked model with  base model and logistic\n",
    "stack_model = StackingClassifier(estimators=estimators_base_model, final_estimator=LogisticRegression(), passthrough=False)\n",
    "\n",
    "# List untuk menyimpan metrik setiap fold\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "# Loop untuk K-Fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_base, y_train_base), 1):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "\n",
    "    # Pisahkan data training dan validasi pada fold ini\n",
    "    X_train_fold, X_val_fold = X_train_base.iloc[train_idx], X_train_base.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_base.iloc[train_idx], y_train_base.iloc[val_idx]\n",
    "\n",
    "    # Train model\n",
    "    stack_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Prediksi pada data validasi\n",
    "    val_predictions = stack_model.predict(X_val_fold)\n",
    "\n",
    "    # Hitung metrik evaluasi\n",
    "    recall = recall_score(y_val_fold, val_predictions)\n",
    "    f1score = f1_score(y_val_fold, val_predictions)\n",
    "    precision = precision_score(y_val_fold, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val_fold, val_predictions)\n",
    "    accuracy = accuracy_score(y_val_fold, val_predictions)\n",
    "\n",
    "    # Simpan hasil metrik di list\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1score)\n",
    "    precision_scores.append(precision)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    # Print hasil per fold\n",
    "    print(f'Fold {fold} - Recall: {recall:.4f}')\n",
    "    print(f'Fold {fold} - F1 Score: {f1score:.4f}')\n",
    "    print(f'Fold {fold} - Precision: {precision:.4f}')\n",
    "    print(f'Fold {fold} - ROC AUC Score: {roc_auc:.4f}')\n",
    "    print(f'Fold {fold} - Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality testing using Shapiro Wilk and T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Shapiro-Wilk Normality Test ===\n",
      "RF: W=0.9483, p-value=0.7250 (Normal)\n",
      "ET: W=0.9325, p-value=0.6139 (Normal)\n",
      "ADA: W=0.9724, p-value=0.8906 (Normal)\n",
      "GB: W=0.9480, p-value=0.7226 (Normal)\n",
      "HGB: W=0.9629, p-value=0.8278 (Normal)\n",
      "XGB: W=0.8548, p-value=0.2100 (Normal)\n",
      "CB: W=0.9451, p-value=0.7020 (Normal)\n",
      "STA: W=0.9143, p-value=0.4939 (Normal)\n",
      "\n",
      "=== Paired T-Test & Wilcoxon Test Against RF ===\n",
      "T-Test STA vs RF: t-stat=0.1192, p-value=0.9109 (Not Significant)\n",
      "T-Test STA vs ET: t-stat=2.6325, p-value=0.0580 (Not Significant)\n",
      "T-Test STA vs ADA: t-stat=2.8666, p-value=0.0456 (Significant)\n",
      "T-Test STA vs GB: t-stat=0.4079, p-value=0.7042 (Not Significant)\n",
      "T-Test STA vs HGB: t-stat=1.1858, p-value=0.3013 (Not Significant)\n",
      "T-Test STA vs XGB: t-stat=1.7053, p-value=0.1633 (Not Significant)\n",
      "T-Test STA vs CB: t-stat=0.7825, p-value=0.4777 (Not Significant)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
    "\n",
    "# Data hasil K-Fold\n",
    "model_RF = np.array([0.8824, 0.8240, 0.8416, 0.8065, 0.9112])\n",
    "model_ET = np.array([0.8313, 0.7456, 0.8503, 0.7752, 0.8712])\n",
    "model_ADA = np.array([0.8008, 0.7785, 0.7538, 0.8257, 0.7993])\n",
    "model_GB = np.array([0.8910, 0.8257, 0.8120, 0.8432, 0.8745])\n",
    "model_HGB = np.array([0.8824, 0.8185, 0.7961, 0.8344, 0.8396])\n",
    "model_XGB = np.array([0.8226, 0.7922, 0.7944, 0.8328, 0.9008])\n",
    "model_CB = np.array([0.8844, 0.7977, 0.8344, 0.8257, 0.9112])\n",
    "model_STA = np.array([0.9017, 0.7873, 0.8344, 0.8381, 0.9112])  \n",
    "\n",
    "# List model untuk perbandingan\n",
    "models = {\n",
    "    \"RF\": model_RF,\n",
    "    \"ET\": model_ET,\n",
    "    \"ADA\": model_ADA,\n",
    "    \"GB\": model_GB,\n",
    "    \"HGB\": model_HGB,\n",
    "    \"XGB\": model_XGB,\n",
    "    \"CB\": model_CB,\n",
    "    \"STA\": model_STA\n",
    "}\n",
    "\n",
    "# Shapiro-Wilk Test untuk normalitas\n",
    "print(\"\\n=== Shapiro-Wilk Normality Test ===\")\n",
    "for name, scores in models.items():\n",
    "    stat, p = shapiro(scores)\n",
    "    print(f\"{name}: W={stat:.4f}, p-value={p:.4f} ({'Normal' if p > 0.05 else 'Non-normal'})\")\n",
    "\n",
    "# Uji T-Test & Wilcoxon antara RF dan model lain\n",
    "print(\"\\n=== Paired T-Test & Wilcoxon Test Against RF ===\")\n",
    "for name, scores in models.items():\n",
    "    if name == \"STA\":\n",
    "        continue  # Skip diri sendiri\n",
    "    \n",
    "    # Uji normalitas kedua model\n",
    "    _, p_rf = shapiro(model_STA)\n",
    "    _, p_model = shapiro(scores)\n",
    "\n",
    "    if p_rf > 0.05 and p_model > 0.05:\n",
    "        # Jika normal, gunakan T-Test\n",
    "        t_stat, p_ttest = ttest_rel(model_STA, scores)\n",
    "        print(f\"T-Test STA vs {name}: t-stat={t_stat:.4f}, p-value={p_ttest:.4f} ({'Significant' if p_ttest < 0.05 else 'Not Significant'})\")\n",
    "    else:\n",
    "        # Jika tidak normal, gunakan Wilcoxon\n",
    "        w_stat, p_wilcoxon = wilcoxon(model_RF, scores)\n",
    "        print(f\"Wilcoxon STA vs {name}: W={w_stat:.4f}, p-value={p_wilcoxon:.4f} ({'Significant' if p_wilcoxon < 0.05 else 'Not Significant'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman Test Statistic: 20.100000000000023, p-value: 0.00047720252711676634\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# Data hasil K-Fold Cross Validation\n",
    "model_RF = np.array([0.8824, 0.8240, 0.8416, 0.8065, 0.9112])\n",
    "model_ET = np.array([0.8313, 0.7456, 0.8503, 0.7752, 0.8712])\n",
    "model_ADA = np.array([0.8008, 0.7785, 0.7538, 0.8257, 0.7993])\n",
    "model_GB = np.array([0.8910, 0.8257, 0.8120, 0.8432, 0.8745])\n",
    "model_HGB = np.array([0.8824, 0.8185, 0.7961, 0.8344, 0.8396])\n",
    "model_XGB = np.array([0.8226, 0.7922, 0.7944, 0.8328, 0.9008])\n",
    "model_CB = np.array([0.8844, 0.7977, 0.8344, 0.8257, 0.9112])\n",
    "model_STA = np.array([0.9017, 0.7873, 0.8344, 0.8381, 0.9112])\n",
    "\n",
    "# Gabungkan data dalam bentuk array (baris = fold, kolom = model)\n",
    "data = np.array([model_RF, model_ET, model_ADA, model_GB, model_HGB, model_XGB, model_CB, model_STA]).T\n",
    "\n",
    "# Friedman Test\n",
    "stat, p_value = friedmanchisquare(*data)\n",
    "\n",
    "print(f\"Friedman Test Statistic: {stat}, p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nemenyi Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting scikit-posthocs\n",
      "\n",
      "  Downloading scikit_posthocs-0.11.4-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-posthocs) (0.13.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-posthocs) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-posthocs) (3.9.2)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-posthocs) (2.2.3)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.4-cp310-cp310-win_amd64.whl (9.8 MB)\n",
      "Requirement already satisfied: scipy>=1.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-posthocs) (1.13.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit-posthocs) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->scikit-posthocs) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->scikit-posthocs) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->scikit-posthocs) (3.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->scikit-posthocs) (4.54.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
      "Collecting patsy>=0.5.6\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels, scikit-posthocs\n",
      "Successfully installed patsy-1.0.1 scikit-posthocs-0.11.4 statsmodels-0.14.4\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Nemenyi Post-hoc Test Results ===\n",
      "           RF        ET       ADA        GB       HGB       XGB        CB  \\\n",
      "RF   1.000000  0.815971  0.216050  0.999829  0.994392  0.924296  1.000000   \n",
      "ET   0.815971  1.000000  0.978833  0.525520  0.996738  0.999996  0.848284   \n",
      "ADA  0.216050  0.978833  1.000000  0.071599  0.701493  0.924296  0.246911   \n",
      "GB   0.999829  0.525520  0.071599  1.000000  0.924296  0.701493  0.999584   \n",
      "HGB  0.994392  0.996738  0.701493  0.924296  1.000000  0.999829  0.996738   \n",
      "XGB  0.924296  0.999996  0.924296  0.701493  0.999829  1.000000  0.942583   \n",
      "CB   1.000000  0.848284  0.246911  0.999584  0.996738  0.942583  1.000000   \n",
      "STA  0.999940  0.570360  0.085327  1.000000  0.942583  0.742183  0.999829   \n",
      "\n",
      "          STA  \n",
      "RF   0.999940  \n",
      "ET   0.570360  \n",
      "ADA  0.085327  \n",
      "GB   1.000000  \n",
      "HGB  0.942583  \n",
      "XGB  0.742183  \n",
      "CB   0.999829  \n",
      "STA  1.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Data hasil K-Fold Cross Validation\n",
    "model_RF = np.array([0.8824, 0.8240, 0.8416, 0.8065, 0.9112])\n",
    "model_ET = np.array([0.8313, 0.7456, 0.8503, 0.7752, 0.8712])\n",
    "model_ADA = np.array([0.8008, 0.7785, 0.7538, 0.8257, 0.7993])\n",
    "model_GB = np.array([0.8910, 0.8257, 0.8120, 0.8432, 0.8745])\n",
    "model_HGB = np.array([0.8824, 0.8185, 0.7961, 0.8344, 0.8396])\n",
    "model_XGB = np.array([0.8226, 0.7922, 0.7944, 0.8328, 0.9008])\n",
    "model_CB = np.array([0.8844, 0.7977, 0.8344, 0.8257, 0.9112])\n",
    "model_STA = np.array([0.9017, 0.7873, 0.8344, 0.8381, 0.9112])\n",
    "\n",
    "# Gabungkan data dalam bentuk array (baris = fold, kolom = model)\n",
    "data = np.array([model_RF, model_ET, model_ADA, model_GB, model_HGB, model_XGB, model_CB, model_STA]).T\n",
    "\n",
    "# Buat dataframe dengan nama model\n",
    "model_names = [\"RF\", \"ET\", \"ADA\", \"GB\", \"HGB\", \"XGB\", \"CB\", \"STA\"]\n",
    "df = pd.DataFrame(data, columns=model_names)\n",
    "\n",
    "# Nemenyi post-hoc test\n",
    "nemenyi_results = sp.posthoc_nemenyi_friedman(df.values)\n",
    "\n",
    "# Tambahkan label model ke hasil\n",
    "nemenyi_results.columns = model_names\n",
    "nemenyi_results.index = model_names\n",
    "\n",
    "print(\"=== Nemenyi Post-hoc Test Results ===\")\n",
    "print(nemenyi_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
