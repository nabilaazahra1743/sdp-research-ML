{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df241cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (rata-rata) of model RF: 0.8098\n",
      "Mean (rata-rata) of model ET: 0.7829\n",
      "Mean (rata-rata) of model ADA: 0.8033\n",
      "Mean (rata-rata) of model GB: 0.7809\n",
      "Mean (rata-rata) of model HGB: 0.7833\n",
      "Mean (rata-rata) of model XGB: 0.8023\n",
      "Mean (rata-rata) of model CB: 0.7882\n",
      "Mean (rata-rata) of model STA: 0.8220\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Model arrays\n",
    "model_RF = np.array([0.8206, 0.7823, 0.7982, 0.7840, 0.8640])\n",
    "model_ET = np.array([0.7628, 0.7352, 0.7982, 0.7664, 0.8520])\n",
    "model_ADA = np.array([0.8120, 0.7599, 0.7703, 0.8120, 0.8624])\n",
    "model_GB = np.array([0.8080, 0.7094, 0.7599, 0.7664, 0.8607])\n",
    "model_HGB = np.array([0.7674, 0.7094, 0.7933, 0.7664, 0.8799])\n",
    "model_XGB = np.array([0.7887, 0.7094, 0.7950, 0.8470, 0.8712])\n",
    "model_CB = np.array([0.7953, 0.7582, 0.7670, 0.7599, 0.8607])\n",
    "model_STA = np.array([0.8399, 0.7823, 0.7895, 0.8152, 0.8832])\n",
    "\n",
    "# Dictionary for easier iteration\n",
    "models = {\n",
    "    \"RF\": model_RF,\n",
    "    \"ET\": model_ET,\n",
    "    \"ADA\": model_ADA,\n",
    "    \"GB\": model_GB,\n",
    "    \"HGB\": model_HGB,\n",
    "    \"XGB\": model_XGB,\n",
    "    \"CB\": model_CB,\n",
    "    \"STA\": model_STA\n",
    "}\n",
    "\n",
    "# Calculate and print mean for each model\n",
    "for name, values in models.items():\n",
    "    mean_val = np.mean(values)\n",
    "    print(f\"Mean (rata-rata) of model {name}: {mean_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64dc834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import tracemalloc\n",
    "import joblib\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d17859d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Evaluation Metrics:\n",
      "Accuracy:  0.6219\n",
      "Precision: 0.1942\n",
      "Recall:    0.7460\n",
      "F1 Score:  0.3082\n",
      "ROC AUC:   0.7106\n",
      "Execution Time: 7.2941 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Start timing and memory tracking\n",
    "start_time = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "# Load model\n",
    "model_path = \"D:/AAAAKK SKRIPSWEETT/Bismillah Code Skripsi V2/model_stack3.pkl\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Load data\n",
    "csv_path = \"D:/AAAAKK SKRIPSWEETT/Bismillah Code Skripsi V2/Dataset/time.csv\"\n",
    "df = pd.read_csv(csv_path, delimiter=\";\")\n",
    "\n",
    "\n",
    "\n",
    "# Kolom yang dibutuhkan\n",
    "selected_columns = [\n",
    "    \"bugs\", \"cbo\", \"dit\", \"fanin\", \"fanout\", \"lcom\", \"noc\", \"loc\", \"rfc\", \"wmc\",\n",
    "    \"totalMethodsQty\", \"protectedMethodsQty\", \"publicMethodsQty\", \"privateMethodsQty\",\n",
    "    \"finalFieldsQty\", \"protectedFieldsQty\", \"publicFieldsQty\", \"privateFieldsQty\", \n",
    "]\n",
    "\n",
    "# Preprocessing\n",
    "df = df.dropna(subset=selected_columns)\n",
    "X = df[[col for col in selected_columns if col != \"bugs\"]]\n",
    "y_true = df[\"bugs\"]\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X)\n",
    "df[\"bug_predicted\"] = y_pred\n",
    "\n",
    "\n",
    "# Probabilities (if supported)\n",
    "try:\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "except AttributeError:\n",
    "    y_proba = None\n",
    "\n",
    "# Save prediction result\n",
    "output_path = csv_path.replace(\"time.csv\", \"time_with_prediction.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Metrics\n",
    "print(\"ðŸ“Š Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "if y_proba is not None:\n",
    "    print(f\"ROC AUC:   {roc_auc_score(y_true, y_proba):.4f}\")\n",
    "else:\n",
    "    print(\"ROC AUC:   Model does not support predict_proba.\")\n",
    "\n",
    "# Execution time\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tracemalloc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Start timing and memory tracking\n",
    "start_time = time.time()\n",
    "tracemalloc.start()\n",
    "\n",
    "# Load model\n",
    "model_path = \"D:/AAAAKK SKRIPSWEETT/Bismillah Code Skripsi V2/model_stack3.pkl\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Load data\n",
    "csv_path = \"D:/AAAAKK SKRIPSWEETT/Bismillah Code Skripsi V2/Dataset/time.csv\"\n",
    "df = pd.read_csv(csv_path, delimiter=\",\")\n",
    "\n",
    "# Kolom yang dibutuhkan\n",
    "selected_columns = [\n",
    "    \"class\", \"cbo\", \"dit\", \"fanin\", \"fanout\", \"lcom\", \"noc\", \"loc\", \"rfc\", \"wmc\",\n",
    "    \"totalMethodsQty\", \"protectedMethodsQty\", \"publicMethodsQty\", \"privateMethodsQty\",\n",
    "    \"finalFieldsQty\", \"protectedFieldsQty\", \"publicFieldsQty\", \"privateFieldsQty\"\n",
    "]\n",
    "\n",
    "# Preprocessing\n",
    "df = df.dropna(subset=selected_columns)\n",
    "X = df[[col for col in selected_columns if col != \"class\"]]\n",
    "y_true = df[\"class\"]\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X)\n",
    "df[\"bug_predicted\"] = y_pred\n",
    "\n",
    "# Pastikan label seragam (hindari campuran string & angka)\n",
    "y_true = y_true.astype(int)\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "\n",
    "# Probabilities (if supported)\n",
    "try:\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "except AttributeError:\n",
    "    y_proba = None\n",
    "\n",
    "# Save prediction result\n",
    "output_path = csv_path.replace(\"time.csv\", \"time_with_prediction.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Metrics\n",
    "print(\"ðŸ“Š Evaluation Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_true, y_pred, zero_division=0):.4f}\")\n",
    "if y_proba is not None:\n",
    "    print(f\"ROC AUC:   {roc_auc_score(y_true, y_proba):.4f}\")\n",
    "else:\n",
    "    print(\"ROC AUC:   Model does not support predict_proba.\")\n",
    "\n",
    "# Execution time\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution Time: {execution_time:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
